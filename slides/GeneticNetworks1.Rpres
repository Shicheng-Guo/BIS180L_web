Genetic Networks 1: Clustering
========================================================
author: Julin Maloof
date: May 28, 2019
autosize: true

Clustering
============

An alternative to doing differential gene expression analysis for RNAseq data is to look for _patterns_ in the data.

This can be particularly uesful as the datsets get larger.

The 12 samples your worked with last week are part of a much larger data set.  Today we will work with 48 samples from the same experiment.

Clustering Goals
==================

1. Identify groups of _samples_ with similar expression patterns (why?)
2. Identify groups of _genes_ with similar expression patterns (why?)

Clustering methods
==================

We will explore three types of clustering:

1. Hierarchical Clustering (today)
2. K-means clustering (today) 
3. Co-expression (Thursday) 

Hierarchical Clustering
=======================

Basic idea:

1. Calculate distances between each pair of samples (or genes)
2. Pair the closest samples together
3. Recalculate distances
4. pair the closest samples
5. repeat 3 and 4

let's try it on some cities

Cities
======
```{r  warning=FALSE, echo=FALSE} 
# make sure to change the path to where you downloaded this using wget
cities <- read.delim("../data/us_cities.txt",row.names = 1)[1:5, 1:5]
knitr::kable(cities)
```

Cities
======
incremental: true
After merging to create a cluster, must re-compute distances from the new mode to all other nodes.  But what value should we use?

```{r warning=FALSE, echo=FALSE}
knitr::kable(cities)
cities2 <- cbind(BOS_NY=NA, cities[2:5,3:5])
cities2[1,] <- NA
rownames(cities2)[1] <- "BOS_NY"
diag(cities2) <- 0
knitr::kable(cities2)
```

Could use minimum, maximum, or average distance.  The default in r `hclust` is maximum

Cities
======
```{r warning=FALSE, echo=FALSE}
knitr::kable(cities)
cities2[1,-1] <- apply(cities[1:2,-1:-2], 2, max)
cities2[-1,1] <- apply(cities[-1:-2,1:2], 1, max)
knitr::kable(cities2)
```

Cities
======
```{r warning=FALSE, echo=FALSE}
knitr::kable(cities2)
cities3 <- cbind(BOS_NY_DC=NA, cities2[-1,-1:-2])
cities3[1,] <- NA
rownames(cities3)[1] <- "BOS_NY_DC"
diag(cities3) <- 0
cities3[1,-1] <- apply(cities2[1:2,-1:-2], 2, max)
cities3[-1,1] <- apply(cities2[-1:-2,1:2], 1, max)
knitr::kable(cities3)
```


K-means clustering
==================

Basic idea:

1. Define the number of clusters desired
2. Randomly assign each gene to a cluster
3. Calculate the mean position of each cluster (aka cluster centroid)
4. Assign each gene to the cluster whose centroid it is closest to
5. Repeat until stable.

K-means animation
==================
```{r, eval=FALSE} 
library(animation) 

kmeans.ani(x = cbind(X1 = runif(50), X2 = runif(50)), centers = 3,
hints = c("Move centers!", "Find cluster?"), pch = 1:3, col = 1:3)
```

K-means animation
==================
```{r, eval=FALSE}
kmeans.ani(x = cbind(X1 = runif(50), X2 = runif(50)), centers = 10,
hints = c("Move centers!", "Find cluster?"), pch = 1:10, col = 1:10)

kmeans.ani(x = cbind(X1 = runif(50), X2 = runif(50)), centers = 5,
hints = c("Move centers!", "Find cluster?"), pch = 1:5, col = 1:5)
```

Gap-statistic
==============
How many clusters are enough?

Calculate within-cluster variance for N random clusters = "Expected"

Calculate within-cluster variance for calcualted K-means clusters = "Observed"

Choose the number of clusters that maximizes the "gap" between observed and expected within-cluster variance.  

